{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "TARGET = \"time_taken\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(data_path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"The file to load does not exist\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def split_data(data: pd.DataFrame, test_size: float, random_state: int):\n",
    "    train_data, test_data = train_test_split(data, \n",
    "                                             test_size=test_size, \n",
    "                                             random_state=random_state)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def read_params(file_path):\n",
    "    with open(file_path,\"r\") as f:\n",
    "        params_file = yaml.safe_load(f)\n",
    "    \n",
    "    return params_file\n",
    "        \n",
    "def save_data(data: pd.DataFrame, save_path: Path) -> None:\n",
    "    data.to_csv(save_path, index=False)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # set file paths\n",
    "    # root path\n",
    "    root_path = Path(__file__).parent.parent.parent\n",
    "    # data load path\n",
    "    data_path = root_path / \"data\" / \"cleaned\" / \"swiggy_cleaned.csv\"\n",
    "    # save data directory\n",
    "    save_data_dir = root_path / \"data\" / \"interim\"\n",
    "    # make dir if not preseny\n",
    "    save_data_dir.mkdir(exist_ok=True,parents=True)\n",
    "    # train and test data save paths\n",
    "    # filenames\n",
    "    train_filename = \"train.csv\"\n",
    "    test_filename = \"test.csv\"\n",
    "    # save path for train and test\n",
    "    save_train_path = save_data_dir / train_filename\n",
    "    save_test_path = save_data_dir / test_filename\n",
    "    # parameters file\n",
    "    params_file_path = root_path / \"params.yaml\"\n",
    "    \n",
    "    # load the cleaned data\n",
    "    df = load_data(data_path)\n",
    "    logger.info(\"Data Loaded Successfully\")\n",
    "    \n",
    "    # read the parameters\n",
    "    parameters = read_params(params_file_path)['Data_Preparation']\n",
    "    test_size = parameters['test_size']\n",
    "    random_state = parameters['random_state']\n",
    "    logger.info(\"parameters read successfully\")\n",
    "    \n",
    "    # split into train and test data\n",
    "    train_data, test_data = split_data(df,test_size=test_size,random_state=random_state)\n",
    "    logger.info(\"Dataset split into train and test data\")\n",
    "    \n",
    "    # save the train and test data\n",
    "    data_subsets = [train_data,test_data]\n",
    "    data_paths = [save_train_path,save_test_path]\n",
    "    filename_list = [train_filename,test_filename]\n",
    "    for filename , path, data in zip(filename_list, data_paths, data_subsets):\n",
    "        save_data(data=data, save_path=path)\n",
    "        logger.info(f\"{filename.replace(\".csv\",\"\")} data saved to location\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
