{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\projects\\\\Delivery-time-prediction-for-food-devlivery-industry\\\\research'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "columns_to_drop =  ['rider_id',\n",
    "                    'restaurant_latitude',\n",
    "                    'restaurant_longitude',\n",
    "                    'delivery_latitude',\n",
    "                    'delivery_longitude',\n",
    "                    'order_date',\n",
    "                    \"order_time_hour\",\n",
    "                    \"order_day\",\n",
    "                    \"city_name\",\n",
    "                    \"order_day_of_week\",\n",
    "                    \"order_month\"]\n",
    "\n",
    "\n",
    "def load_data(data_path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"The file to load does not exist\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def change_column_names(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        data.rename(str.lower,axis=1)\n",
    "        .rename({\n",
    "            \"delivery_person_id\" : \"rider_id\",\n",
    "            \"delivery_person_age\": \"age\",\n",
    "            \"delivery_person_ratings\": \"ratings\",\n",
    "            \"delivery_location_latitude\": \"delivery_latitude\",\n",
    "            \"delivery_location_longitude\": \"delivery_longitude\",\n",
    "            \"time_orderd\": \"order_time\",\n",
    "            \"time_order_picked\": \"order_picked_time\",\n",
    "            \"weatherconditions\": \"weather\",\n",
    "            \"road_traffic_density\": \"traffic\",\n",
    "            \"city\": \"city_type\",\n",
    "            \"time_taken(min)\": \"time_taken\"},axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "def data_cleaning(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    minors_data = data.loc[data['age'].astype('float') < 18]\n",
    "    minor_index = minors_data.index.tolist()\n",
    "    six_star_data = data.loc[data['ratings'] == \"6\"]\n",
    "    six_star_index = six_star_data.index.tolist()\n",
    "\n",
    "    return (\n",
    "        data\n",
    "        .drop(columns=\"id\")\n",
    "        .drop(index=minor_index)                                                # Minor riders in data dropped\n",
    "        .drop(index=six_star_index)                                             # six star rated drivers dropped\n",
    "        .replace(\"NaN \",np.nan)                                                 # missing values in the data\n",
    "        .assign(\n",
    "            # city column out of rider id\n",
    "            city_name = lambda x: x['rider_id'].str.split(\"RES\").str.get(0),\n",
    "            # convert age to float\n",
    "            age = lambda x: x['age'].astype(float),\n",
    "            # convert ratings to float\n",
    "            ratings = lambda x: x['ratings'].astype(float),\n",
    "            # absolute values for location based columns\n",
    "            restaurant_latitude = lambda x: x['restaurant_latitude'].abs(),\n",
    "            restaurant_longitude = lambda x: x['restaurant_longitude'].abs(),\n",
    "            delivery_latitude = lambda x: x['delivery_latitude'].abs(),\n",
    "            delivery_longitude = lambda x: x['delivery_longitude'].abs(),\n",
    "            # order date to datetime and feature extraction\n",
    "            order_date = lambda x: pd.to_datetime(x['order_date'],\n",
    "                                                  dayfirst=True),\n",
    "            order_day = lambda x: x['order_date'].dt.day,\n",
    "            order_month = lambda x: x['order_date'].dt.month,\n",
    "            order_day_of_week = lambda x: x['order_date'].dt.day_name().str.lower(),\n",
    "            is_weekend = lambda x: (x['order_date']\n",
    "                                    .dt.day_name()\n",
    "                                    .isin([\"Saturday\",\"Sunday\"])\n",
    "                                    .astype(int)),\n",
    "            # time based columns\n",
    "            order_time = lambda x: pd.to_datetime(x['order_time'],\n",
    "                                                  format='mixed'),\n",
    "            order_picked_time = lambda x: pd.to_datetime(x['order_picked_time'],\n",
    "                                                         format='mixed'),\n",
    "            # time taken to pick order\n",
    "            pickup_time_minutes = lambda x: (\n",
    "                                            (x['order_picked_time'] - x['order_time'])\n",
    "                                            .dt.seconds / 60\n",
    "                                            ),\n",
    "            # hour in which order was placed\n",
    "            order_time_hour = lambda x: x['order_time'].dt.hour,\n",
    "            # time of the day when order was placed\n",
    "            order_time_of_day = lambda x: (\n",
    "                                x['order_time_hour'].pipe(time_of_day)),\n",
    "            # categorical columns\n",
    "            weather = lambda x: (\n",
    "                                x['weather']\n",
    "                                .str.replace(\"conditions \",\"\")\n",
    "                                .str.lower()\n",
    "                                .replace(\"nan\",np.nan)),\n",
    "            traffic = lambda x: x[\"traffic\"].str.rstrip().str.lower(),\n",
    "            type_of_order = lambda x: x['type_of_order'].str.rstrip().str.lower(),\n",
    "            type_of_vehicle = lambda x: x['type_of_vehicle'].str.rstrip().str.lower(),\n",
    "            festival = lambda x: x['festival'].str.rstrip().str.lower(),\n",
    "            city_type = lambda x: x['city_type'].str.rstrip().str.lower(),\n",
    "            # multiple deliveries column\n",
    "            multiple_deliveries = lambda x: x['multiple_deliveries'].astype(float),\n",
    "            # target column modifications\n",
    "            time_taken = lambda x: (x['time_taken']\n",
    "                                    .str.replace(\"(min) \",\"\")\n",
    "                                    .astype(int)))\n",
    "        .drop(columns=[\"order_time\",\"order_picked_time\"])\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "def clean_lat_long(data: pd.DataFrame, threshold: float=1.0) -> pd.DataFrame:\n",
    "    location_columns = ['restaurant_latitude',\n",
    "                        'restaurant_longitude',\n",
    "                        'delivery_latitude',\n",
    "                        'delivery_longitude']\n",
    "\n",
    "    return (\n",
    "        data\n",
    "        .assign(**{\n",
    "            col: (\n",
    "                np.where(data[col] < threshold, np.nan, data[col].values)\n",
    "            )\n",
    "            for col in location_columns\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    \n",
    "# extract day, day name, month and year\n",
    "def extract_datetime_features(ser: pd.Series) -> pd.DataFrame:\n",
    "    date_col = pd.to_datetime(ser,dayfirst=True)\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"day\": date_col.dt.day,\n",
    "                \"month\": date_col.dt.month,\n",
    "                \"year\": date_col.dt.year,\n",
    "                \"day_of_week\": date_col.dt.day_name(),\n",
    "                \"is_weekend\": date_col.dt.day_name().isin([\"Saturday\",\"Sunday\"]).astype(int)\n",
    "            }\n",
    "        ))\n",
    "    \n",
    "\n",
    "    \n",
    "def time_of_day(ser: pd.Series):\n",
    "\n",
    "    return(\n",
    "        pd.cut(ser,bins=[0,6,12,17,20,24],right=True,\n",
    "               labels=[\"after_midnight\",\"morning\",\"afternoon\",\"evening\",\"night\"])\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def calculate_haversine_distance(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    location_columns = ['restaurant_latitude',\n",
    "                        'restaurant_longitude',\n",
    "                        'delivery_latitude',\n",
    "                        'delivery_longitude']\n",
    "    \n",
    "    lat1 = df[location_columns[0]]\n",
    "    lon1 = df[location_columns[1]]\n",
    "    lat2 = df[location_columns[2]]\n",
    "    lon2 = df[location_columns[3]]\n",
    "\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(\n",
    "        dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    distance = 6371 * c\n",
    "\n",
    "    return (\n",
    "        df.assign(\n",
    "            distance = distance)\n",
    "    )\n",
    "\n",
    "\n",
    "def create_distance_type(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return(\n",
    "        data\n",
    "        .assign(\n",
    "                distance_type = pd.cut(data[\"distance\"],bins=[0,5,10,15,25],\n",
    "                                        right=False,labels=[\"short\",\"medium\",\"long\",\"very_long\"])\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "def drop_columns(data: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df = data.drop(columns=columns)\n",
    "    return df\n",
    " \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "cwd = Path.cwd()  # Get current working directory\n",
    "root_path = cwd.parent\n",
    "# root_path = Path(__file__).parent.parent.parent\n",
    "# print(root_path)\\\n",
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "cleaned_data_save_dir = root_path / \"data\" /\"cleaned\"\n",
    "\n",
    "cleaned_data_save_dir.mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "cleaned_data_filename = \"swiggy_cleaned.csv\"\n",
    "\n",
    "cleaned_data_save_path = cleaned_data_save_dir / cleaned_data_filename\n",
    "\n",
    "data_load_path = root_path / \"data\" / \"raw\" /\"swiggy.csv\"\n",
    "\n",
    "#data_load_path = \"https://raw.githubusercontent.com/onkar-git/Delivery-time-prediction-for-food-delivery-industry/refs/heads/main/swiggy.csv\"\n",
    "\n",
    "#data_load_path = root_path / \"data\" / \"raw\" /\"swiggy.csv\"\n",
    "\n",
    "df = load_data(data_load_path)\n",
    "\n",
    "\n",
    "#perform_data_cleaning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_data_cleaning(data: pd.DataFrame, saved_data_path: Path) -> None:\n",
    "    \n",
    "    cleaned_data = (\n",
    "        data\n",
    "        .pipe(change_column_names)\n",
    "        .pipe(data_cleaning)\n",
    "        .pipe(clean_lat_long)\n",
    "        .pipe(calculate_haversine_distance)\n",
    "        .pipe(create_distance_type)\n",
    "        .pipe(drop_columns,columns=columns_to_drop)\n",
    "    )\n",
    "    return cleaned_data.dropna()\n",
    "\n",
    "    # save the data\n",
    "    cleaned_data.to_csv(saved_data_path,index=False)\n",
    "saved_data_path=cleaned_data_save_path\n",
    "cleaned_data=perform_data_cleaning(data=df,saved_data_path=cleaned_data_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv(saved_data_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: Path\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Deliveryprediction.constants import *\n",
    "from Deliveryprediction.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from Deliveryprediction import logger\n",
    "from Deliveryprediction.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIG_FILE_PATH = Path(\"E:\\projects\\Delivery-time-prediction-for-food-devlivery-industry\\config\\config.yaml\")\n",
    "PARAMS_FILE_PATH = Path(\"E:\\projects\\Delivery-time-prediction-for-food-devlivery-industry\\params.yaml\")\n",
    "SCHEMA_FILE_PATH = Path(\"E:\\projects\\Delivery-time-prediction-for-food-devlivery-industry\\schema.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-08 14:38:09,179: INFO: common: yaml file: E:\\projects\\Delivery-time-prediction-for-food-devlivery-industry\\config\\config.yaml loaded successfully]\n",
      "[2025-02-08 14:38:09,182: INFO: common: yaml file: E:\\projects\\Delivery-time-prediction-for-food-devlivery-industry\\params.yaml loaded successfully]\n",
      "[2025-02-08 14:38:09,184: INFO: common: yaml file: E:\\projects\\Delivery-time-prediction-for-food-devlivery-industry\\schema.yaml loaded successfully]\n",
      "[2025-02-08 14:38:09,186: INFO: common: created directory at: artifacts]\n",
      "[2025-02-08 14:38:09,187: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-02-08 14:38:11,034: INFO: 3447005916: artifacts/data_ingestion/data.csv download! with following info: \n",
      "Connection: close\n",
      "Content-Length: 7772212\n",
      "Cache-Control: max-age=300\n",
      "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
      "Content-Type: text/plain; charset=utf-8\n",
      "ETag: \"86298f701a3f9ded8ac62fcba0c8565015e96ff7ca601d0c221444020783af2e\"\n",
      "Strict-Transport-Security: max-age=31536000\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: deny\n",
      "X-XSS-Protection: 1; mode=block\n",
      "X-GitHub-Request-Id: A373:361DE1:1918DC:25BB1E:67A71D54\n",
      "Accept-Ranges: bytes\n",
      "Date: Sat, 08 Feb 2025 09:08:09 GMT\n",
      "Via: 1.1 varnish\n",
      "X-Served-By: cache-maa10242-MAA\n",
      "X-Cache: HIT\n",
      "X-Cache-Hits: 1\n",
      "X-Timer: S1739005690.659000,VS0,VE8\n",
      "Vary: Authorization,Accept-Encoding,Origin\n",
      "Access-Control-Allow-Origin: *\n",
      "Cross-Origin-Resource-Policy: cross-origin\n",
      "X-Fastly-Request-ID: 741a24b13305ad5608c6834b55f83a5962713462\n",
      "Expires: Sat, 08 Feb 2025 09:13:09 GMT\n",
      "Source-Age: 47\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    #data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "from Deliveryprediction import logger\n",
    "import json\n",
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"reads yaml file and returns\n",
    "\n",
    "    Args:\n",
    "        path_to_yaml (str): path like input\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if yaml file is empty\n",
    "        e: empty file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: ConfigBox type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(content)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"yaml file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting box\n",
      "  Downloading box-0.1.5-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiohttp>=3.8.1 (from box)\n",
      "  Downloading aiohttp-3.10.11-cp38-cp38-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting columnar==1.3.1 (from box)\n",
      "  Downloading Columnar-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting executing==0.8.2 (from box)\n",
      "  Downloading executing-0.8.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting loguru (from box)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting python-dateutil==2.8.2 (from box)\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting timeago==1.0.14 (from box)\n",
      "  Downloading timeago-1.0.14.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting toolz (from columnar==1.3.1->box)\n",
      "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\admin\\.conda\\envs\\mlproj\\lib\\site-packages (from columnar==1.3.1->box) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\mlproj\\lib\\site-packages (from python-dateutil==2.8.2->box) (1.16.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.8.1->box)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp>=3.8.1->box)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp>=3.8.1->box)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.8.1->box)\n",
      "  Downloading frozenlist-1.5.0-cp38-cp38-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.8.1->box)\n",
      "  Downloading multidict-6.1.0-cp38-cp38-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp>=3.8.1->box)\n",
      "  Downloading yarl-1.15.2-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp>=3.8.1->box)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\admin\\.conda\\envs\\mlproj\\lib\\site-packages (from loguru->box) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru->box)\n",
      "  Downloading win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\admin\\.conda\\envs\\mlproj\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp>=3.8.1->box) (4.12.2)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.12.0->aiohttp>=3.8.1->box)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp>=3.8.1->box)\n",
      "  Downloading propcache-0.2.0-cp38-cp38-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading box-0.1.5-py3-none-any.whl (162 kB)\n",
      "Downloading Columnar-1.3.1-py3-none-any.whl (11 kB)\n",
      "Downloading executing-0.8.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Downloading aiohttp-3.10.11-cp38-cp38-win_amd64.whl (384 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp38-cp38-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Downloading win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
      "Downloading yarl-1.15.2-cp38-cp38-win_amd64.whl (84 kB)\n",
      "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading propcache-0.2.0-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Building wheels for collected packages: timeago\n",
      "  Building wheel for timeago (setup.py): started\n",
      "  Building wheel for timeago (setup.py): finished with status 'done'\n",
      "  Created wheel for timeago: filename=timeago-1.0.14-py3-none-any.whl size=26462 sha256=3f8513cb7b6f55176c65e41b7f0387b1df867093969f50e154f0b57a3ee7e456\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\fc\\62\\5f\\e3cc9a2e1f65da6eaa8bce5e2c291622981c4596e228aa83fa\n",
      "Successfully built timeago\n",
      "Installing collected packages: timeago, executing, win32-setctime, toolz, python-dateutil, propcache, multidict, idna, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, loguru, columnar, aiosignal, aiohttp, box\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 2.1.0\n",
      "    Uninstalling executing-2.1.0:\n",
      "      Successfully uninstalled executing-2.1.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0\n",
      "    Uninstalling python-dateutil-2.9.0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 attrs-25.1.0 box-0.1.5 columnar-1.3.1 executing-0.8.2 frozenlist-1.5.0 idna-3.10 loguru-0.7.3 multidict-6.1.0 propcache-0.2.0 python-dateutil-2.8.2 timeago-1.0.14 toolz-1.0.0 win32-setctime-1.2.0 yarl-1.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stack-data 0.6.2 requires executing>=1.2.0, but you have executing 0.8.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-08 11:22:58,840: ERROR: 1539134077: Error reading YAML: YAML file config\\config.yaml not found.]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "YAML file config\\config.yaml not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m config_filepath \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mread_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[49], line 35\u001b[0m, in \u001b[0;36mread_yaml\u001b[1;34m(path_to_yaml)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     34\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading YAML: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[49], line 22\u001b[0m, in \u001b[0;36mread_yaml\u001b[1;34m(path_to_yaml)\u001b[0m\n\u001b[0;32m     20\u001b[0m path_to_yaml \u001b[38;5;241m=\u001b[39m Path(path_to_yaml)  \u001b[38;5;66;03m# Ensure it's a Path object\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path_to_yaml\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYAML file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_yaml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_to_yaml, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n\u001b[0;32m     25\u001b[0m     content \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(yaml_file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: YAML file config\\config.yaml not found."
     ]
    }
   ],
   "source": [
    "config_filepath = Path(\"config/config.yaml\")\n",
    "config = read_yaml(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigBox({'key': 'val'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
